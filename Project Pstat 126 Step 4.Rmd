---
title: "Project Pstat 126 Step 4"
author: "Kenny"
output: html_document
date: "2023-06-01"
---
```{r setup, include = FALSE}
# default code chunk options
knitr::opts_chunk$set(echo = T,
                      results = 'markup',
                      message = F, 
                      warning = F,
                      fig.width = 4,
                      fig.height = 3,
                      fig.align = 'center') 

# load packages
library(faraway)
library(tidyverse)
library(tidymodels)
library(modelr)
library(ggplot2)
library(glmnet)
```


Introduction: (Quickly reacquaint the reader with the relevant variables). Ensure to
include a citation for the original data source, and clarify the population to which your
results are being inferred.
```{r}

income_data <- read.csv("~/downloads/PSTAT126_Project-main/adult-copy.csv")
head(income_data)

```


• Execute both ridge regression (RR) and LASSO on the complete variable set (use cross-
validation to find lambda). Analyze and differentiate the models (i.e., coeﬀicients) with
the final MLR model from the previous project task.
```{r MLR Model, fig.show='show', echo=FALSE}

#Ridge Regression for variables 

#response variable
y <- income_data$educational.num

#define the matrix of the predictor variables
x <- data.matrix(income_data[, c('age', 'fnlwgt', 'hours.per.week')])

#fit Ridge Regression Model
model <- glmnet(x, y, alpha = 0)

#summary of the model
summary(model)

#performing k-fold cross_validation in order to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 0)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda

#produce plot of test MSE by lambda value
plot(cv_model)

#find coefficients of best model
best_model <- glmnet(x, y, alpha = 0, lamba = best_lambda)
coef(best_model)

#ridge trace plot 
plot(model, xvar = "lambda")

#using best fitted model to make predictions

y_predicted <- predict(model, s = best_lambda, newx = x)

#calculating R^2 and SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)

r_2 <- 1 - sse/sst
r_2

#the ridge regression provided gives a value for R^2 as 0.0004896063. 


```


```{r LASSO Regression Model, fig.show= 'show', echo = FALSE}
#LASSO Regression

#response variable
y <- income_data$educational.num

#define the matrix of the predictor variables
x <- data.matrix(income_data[, c('age', 'fnlwgt', 'hours.per.week')])

# perform k-fold cross validation to find optimal lambda value
cv_model2 <- cv.glmnet(x, y, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda2 <- cv_model2$lambda.min
best_lambda2

#producing plot of test MSE by lambda value
plot(cv_model2)

#Analyzing final model
#finding coefficients of best model

best_model2 <- glmnet(x, y, alpha = 1, lambda = best_lambda2)
coef(best_model2)


#using best fitted model to make predictions

y_predicted2 <- predict(model, s = best_lambda2, newx = x)


#calculating R^2 and SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted2 - y)^2)

r_2 <- 1 - sse/sst
r_2

#the LASSO regression also provides a value for R^2 as 0.0004896063. 

```



• Construct a single graph with the observed response variable on the x-axis and the
predicted response variable on the y-axis. Superimpose (using color with a legend) 3
different predictions: MLR, RR, LASSO. Provide a commentary on the figure.
```{r Plotted Graph of MLR, LASSO, and Ridge in one, fig.show= 'show', echo= FALSE}

# Assuming you have the necessary data and models already defined and loaded

# Create a dataframe to store the observed and predicted values
results <- data.frame(Observed = income_data$educational.num)

# Matrix of predictor variables
predictors <- data.matrix(income_data[, c('age', 'fnlwgt', 'hours.per.week')])

# Predict using the MLR model
results$MLR_Prediction <- predict(MLR_model, newdata = predictors)

# Predict using the RR model
results$RR_Prediction <- predict(RR_model, newdata = predictors)

# Predict using the LASSO model
results$LASSO_Prediction <- predict(LASSO_model, newdata = predictors)

# Plotting the graph
plot(results$Observed, results$MLR_Prediction, type = "n", xlab = "Observed", ylab = "Predicted")
points(results$Observed, results$MLR_Prediction, col = "blue", pch = 16)
points(results$Observed, results$RR_Prediction, col = "red", pch = 16)
points(results$Observed, results$LASSO_Prediction, col = "green", pch = 16)

# Adding a legend
legend("topright", legend = c("MLR", "RR", "LASSO"), col = c("blue", "red", "green"), pch = 16)

# Commentary on the figure
# The graph displays the observed response variable (educational.num) on the x-axis and the predicted response variable on the y-axis.
# The blue dots represent the predictions made by the MLR (Multiple Linear Regression) model.
# The red dots represent the predictions made by the RR (Ridge Regression) model.
# The green dots represent the predictions made by the LASSO (Least Absolute Shrinkage and Selection Operator) model.
# By superimposing these predictions, we can visually compare how well each model fits the observed educational levels.


```



• Conclusion (Sum up your results. Discuss any notable happenings. Were the data largely
as you anticipated or were there surprising results? What further queries would you like
to explore about the data?)

```{r Summarization of Data Collected, fig.show='show', echo=FALSE}
#will do all together


```


Innovation:
• Execute at least one analysis technique that hasn’t been covered in class.

```{r Bootstraping, fig.show = 'show', echo=FALSE}
library(boot)
y <- income_data$educational.num
x <- data.matrix(income_data[, c('age', 'fnlwgt', 'hours.per.week')])

# Creating Function to obtain R-Squared from the data
r_squared <- function(formula, data, indices) {
val <- data[indices,] # selecting sample with boot 
fit <- lm(formula, data=val)
return(summary(fit)$r.square)
} 

# Performing 500 replications with boot 
output <- boot(data=income_data, statistic=r_squared, 
R=100, formula= y ~ x)

# Plotting the output
output 
plot(output)

# Obtaining a confidence interval of 95%
boot.ci(output, type="bca")

```


• Justify your choice of method(s). That is, why is it suitable for your data? Explain the
importance of this method in comprehending your data’s complete analysis.

```{r Context of Bootstraping, fig.show ='show' , echo=FALSE}


#The reason we chose to use the Bootstrap model is because this model is a non parametric estimation method ideal for when the distribution of a statistic is unknown or complicated. In our dataset, final weight is classified as a complicated statistic being estimated from multiple parameters. Luckily, the bootstrap method does not ask for specific distribution methods, so finding the correlation between for example education and final weight can be achieved. The output of our bootstrap gives us a better understanding of this comparison as opposed to other methods. 

```

• Provide some context/theory to the method (demonstrate your comprehension of the new
method). This is essential! For instance, describe the derivation and intuition behind
a new test statistic. Share as much detail as possible about your understanding of the
new concept.

```{r}
#Bootstrapping is mainly the re sampling of the data provided in order to create more stimulated samples. The purpose of this is to calculate standard errors, t values, and create confidence for a wide set of stimulated samples. It also calculates how variable the model parameters due to the small changes in data values. This affects the regression coefficients and the variation of the parameters. 

```


• What technical conditions are vital for the model? How do the results react to these
conditions? Were any of these violated?

```{r}
# The technical specifications for this model can be broken down into a few steps. Firstly being how many samples needed to be performed in order to generate an ideal bootstrap statistic. Next for each sample, we need to specify the sample size. We chose to do 400, thanks to the professor's recommendations as to a quality sample size in class. The next specification is that the bootstrap model calculates a statistic of interest for each sample. Lastly, the mean is calculated from each sample statistic. Without these specifications, the bootstrap statistic cannot be generated correctly. Our bootstrap sample generated what seems to be an appropriate statistic of interest. In our case a t value of 0.024 was generated.

```

